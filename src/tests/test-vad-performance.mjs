#!/usr/bin/env node\n/**\n * VAD Performance Test Script\n * \n * Demonstrates VAD optimization capabilities and performance testing.\n * This script can be used to test different VAD configurations and optimize\n * for specific environments.\n */\n\nimport {VADManager} from './src/services/voice-activity-detector.js'\nimport {VADPerformanceOptimizer} from './src/services/vad-performance-optimizer.js'\nimport {VADConfigurationManager} from './src/services/vad-configuration-manager.js'\n\n/**\n * Generate synthetic audio data for testing\n */\nfunction generateTestAudioData(durationMs, type = 'silence', sampleRate = 16000) {\n  const sampleCount = Math.floor((durationMs / 1000) * sampleRate)\n  const audioData = new Float32Array(sampleCount)\n  \n  switch (type) {\n    case 'speech':\n      // Generate speech-like signal (sine wave with noise)\n      for (let i = 0; i < sampleCount; i++) {\n        const frequency = 200 + Math.random() * 300 // 200-500 Hz range\n        const signal = Math.sin(2 * Math.PI * frequency * i / sampleRate) * 0.3\n        const noise = (Math.random() - 0.5) * 0.1\n        audioData[i] = signal + noise\n      }\n      break\n    \n    case 'noise':\n      // Generate noise\n      for (let i = 0; i < sampleCount; i++) {\n        audioData[i] = (Math.random() - 0.5) * 0.2\n      }\n      break\n    \n    case 'silence':\n    default:\n      // Keep as zeros (silence)\n      break\n  }\n  \n  return audioData\n}\n\n/**\n * Test basic VAD functionality\n */\nasync function testBasicVAD() {\n  console.log('\\n=== Testing Basic VAD Functionality ===')\n  \n  const vadManager = new VADManager({\n    threshold: 0.3,\n    minSpeechDuration: 300,\n    maxSilenceDuration: 2000\n  })\n  \n  await vadManager.initialize()\n  vadManager.start()\n  \n  // Test with different audio types\n  const testCases = [\n    {type: 'silence', duration: 500, expected: 'silence'},\n    {type: 'speech', duration: 800, expected: 'speech'},\n    {type: 'noise', duration: 300, expected: 'silence'}, // noise should be filtered out\n    {type: 'speech', duration: 1200, expected: 'speech'},\n    {type: 'silence', duration: 1000, expected: 'silence'}\n  ]\n  \n  console.log('Processing test audio samples...')\n  \n  for (const testCase of testCases) {\n    const audioData = generateTestAudioData(testCase.duration, testCase.type)\n    const result = vadManager.processAudioChunk(audioData, Date.now())\n    \n    console.log(`${testCase.type.padEnd(8)} (${testCase.duration}ms): ${\n      result ? `${result.type} (confidence: ${result.confidence.toFixed(3)})` : 'no event'\n    }`)\n  }\n  \n  const metrics = vadManager.getMetrics()\n  console.log('\\nVAD Metrics:')\n  console.log(`  Analyzed frames: ${metrics.totalAnalyzedFrames}`)\n  console.log(`  Speech frames: ${metrics.speechFrames}`)\n  console.log(`  Silence frames: ${metrics.silenceFrames}`)\n  console.log(`  Average confidence: ${metrics.averageConfidence.toFixed(3)}`)\n  console.log(`  Processing latency: ${metrics.processingLatency.toFixed(2)}ms`)\n  \n  vadManager.stop()\n  vadManager.destroy()\n}\n\n/**\n * Test VAD performance optimization\n */\nasync function testVADOptimization() {\n  console.log('\\n=== Testing VAD Performance Optimization ===')\n  \n  const vadManager = new VADManager()\n  await vadManager.initialize()\n  vadManager.start()\n  \n  const optimizer = new VADPerformanceOptimizer(vadManager)\n  \n  console.log('Available optimization profiles:')\n  const profiles = optimizer.getOptimizationProfiles()\n  profiles.forEach(profile => {\n    console.log(`  ${profile.name}: ${profile.environment} environment`)\n    console.log(`    Expected latency: ${profile.expectedPerformance.maxLatency}ms`)\n    console.log(`    Expected accuracy: ${(profile.expectedPerformance.minAccuracy * 100).toFixed(1)}%`)\n  })\n  \n  // Test optimization for normal environment\n  console.log('\\nOptimizing for normal environment...')\n  try {\n    const result = await optimizer.optimizeForEnvironment('normal', 10000) // 10 second test\n    \n    console.log('Optimization Results:')\n    console.log(`  Latency reduction: ${result.performanceImprovement.latencyReduction.toFixed(2)}%`)\n    console.log(`  Accuracy improvement: ${result.performanceImprovement.accuracyImprovement.toFixed(2)}%`)\n    console.log(`  Throughput increase: ${result.performanceImprovement.throughputIncrease.toFixed(2)}%`)\n    \n    if (result.recommendations.length > 0) {\n      console.log('  Recommendations:')\n      result.recommendations.forEach(rec => {\n        console.log(`    - ${rec}`)\n      })\n    }\n  } catch (error) {\n    console.log(`  Optimization test skipped: ${error.message}`)\n  }\n  \n  vadManager.stop()\n  vadManager.destroy()\n}\n\n/**\n * Test configuration management\n */\nasync function testConfigurationManager() {\n  console.log('\\n=== Testing Configuration Management ===')\n  \n  const configManager = new VADConfigurationManager()\n  \n  // Show available sensitivity presets\n  console.log('Available sensitivity presets:')\n  const presets = configManager.getAllSensitivityPresets()\n  presets.forEach(preset => {\n    console.log(`  ${preset.name}: ${preset.description}`)\n    console.log(`    Threshold: ${preset.config.threshold}`)\n    console.log(`    Use cases: ${preset.useCase.join(', ')}`)\n  })\n  \n  // Show available configuration profiles\n  console.log('\\nAvailable configuration profiles:')\n  const profiles = configManager.getAllConfigurationProfiles()\n  profiles.forEach(profile => {\n    console.log(`  ${profile.name}: ${profile.environmentType} environment`)\n    console.log(`    Sensitivity: ${profile.sensitivityPreset}`)\n    console.log(`    Dynamic adjustment: ${profile.dynamicAdjustment.enabled ? 'enabled' : 'disabled'}`)\n  })\n  \n  // Test profile application\n  console.log('\\nApplying \"video_call\" profile...')\n  const config = configManager.applyConfigurationProfile('video_call')\n  if (config) {\n    console.log('Applied configuration:')\n    console.log(`  Threshold: ${config.threshold}`)\n    console.log(`  Min speech duration: ${config.minSpeechDuration}ms`)\n    console.log(`  Interruption enabled: ${config.enableInterruption}`)\n  }\n  \n  // Test recommendation system\n  const recommendation = configManager.getRecommendedProfile('noisy', 'meeting')\n  if (recommendation) {\n    console.log(`\\nRecommended profile for noisy meeting: ${recommendation.name}`)\n  }\n  \n  // Create custom profile\n  const customCreated = configManager.createCustomProfile(\n    'my_custom_profile',\n    'My Custom Profile',\n    'balanced',\n    'normal',\n    {\n      threshold: 0.4,\n      minSpeechDuration: 250\n    },\n    {\n      enabled: true,\n      adaptationSpeed: 'fast'\n    }\n  )\n  \n  if (customCreated) {\n    console.log('\\nCreated custom profile successfully!')\n  }\n}\n\n/**\n * Test calibration system\n */\nasync function testCalibrationSystem() {\n  console.log('\\n=== Testing Calibration System ===')\n  \n  const vadManager = new VADManager()\n  await vadManager.initialize()\n  vadManager.start()\n  \n  const optimizer = new VADPerformanceOptimizer(vadManager)\n  \n  console.log('Starting calibration session...')\n  const sessionId = await optimizer.startCalibration('test_environment')\n  console.log(`Calibration session started: ${sessionId}`)\n  \n  // Add test samples\n  const testSamples = [\n    {audio: generateTestAudioData(500, 'speech'), expected: 'speech'},\n    {audio: generateTestAudioData(300, 'silence'), expected: 'silence'},\n    {audio: generateTestAudioData(800, 'speech'), expected: 'speech'},\n    {audio: generateTestAudioData(200, 'noise'), expected: 'silence'},\n    {audio: generateTestAudioData(600, 'speech'), expected: 'speech'},\n    {audio: generateTestAudioData(1000, 'silence'), expected: 'silence'}\n  ]\n  \n  console.log('Adding calibration samples...')\n  testSamples.forEach((sample, index) => {\n    optimizer.addCalibrationSample(sample.audio, sample.expected)\n    console.log(`  Sample ${index + 1}: ${sample.expected} (${sample.audio.length} samples)`)\n  })\n  \n  // Complete calibration\n  const calibrationResult = await optimizer.completeCalibration()\n  \n  console.log('\\nCalibration Results:')\n  console.log(`  Accuracy: ${(calibrationResult.metrics.accuracy * 100).toFixed(1)}%`)\n  console.log(`  Average latency: ${calibrationResult.metrics.averageLatency.toFixed(2)}ms`)\n  console.log(`  False positive rate: ${(calibrationResult.metrics.falsePositiveRate * 100).toFixed(1)}%`)\n  console.log(`  False negative rate: ${(calibrationResult.metrics.falseNegativeRate * 100).toFixed(1)}%`)\n  \n  if (calibrationResult.recommendations.length > 0) {\n    console.log('  Recommendations:')\n    calibrationResult.recommendations.forEach(rec => {\n      console.log(`    - ${rec}`)\n    })\n  }\n  \n  console.log('\\nOptimized configuration:')\n  Object.entries(calibrationResult.optimizedConfig).forEach(([key, value]) => {\n    console.log(`  ${key}: ${value}`)\n  })\n  \n  vadManager.stop()\n  vadManager.destroy()\n}\n\n/**\n * Main test function\n */\nasync function main() {\n  console.log('VAD Performance Test Suite')\n  console.log('==========================')\n  \n  try {\n    await testBasicVAD()\n    await testVADOptimization()\n    await testConfigurationManager()\n    await testCalibrationSystem()\n    \n    console.log('\\n=== All tests completed successfully! ===')\n  } catch (error) {\n    console.error('\\nTest failed:', error.message)\n    console.error('Stack trace:', error.stack)\n    process.exit(1)\n  }\n}\n\n// Run tests if this script is executed directly\nif (import.meta.url === `file://${process.argv[1]}`) {\n  main().catch(console.error)\n}\n\nexport {\n  testBasicVAD,\n  testVADOptimization,\n  testConfigurationManager,\n  testCalibrationSystem\n}